{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f02d5168-3a0a-4d61-8005-47e48a5baf00","showTitle":false,"title":""},"vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["The code failed because of a fatal error:\n","\tError sending http request and maximum retry encountered..\n","\n","Some things to try:\n","a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n","b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n","c) Restart the kernel.\n"]}],"source":["import org.apache.spark.sql.SparkSession"]},{"cell_type":"code","execution_count":2,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["The code failed because of a fatal error:\n","\tError sending http request and maximum retry encountered..\n","\n","Some things to try:\n","a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n","b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n","c) Restart the kernel.\n"]}],"source":["val spark = sparkSession.builder().getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"92cc9f9d-02be-4709-84db-28d833776f93","showTitle":false,"title":""},"vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["The code failed because of a fatal error:\n","\tError sending http request and maximum retry encountered..\n","\n","Some things to try:\n","a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n","b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n","c) Restart the kernel.\n"]}],"source":["brasileirao = spark.read.format(\"csv\")\n","                .option(\"header\", \"true\")\n","                .option(\"delimiter\", \",\")\n","                .option(\"encoding\", \"Utf-8\")\n","                .load(\"/FileStore/tables/nttdata/scala-spark/campeonato_brasileiro_full.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"26314954-b34d-4857-a7dc-cb1eb2667006","showTitle":false,"title":""},"vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["The code failed because of a fatal error:\n","\tError sending http request and maximum retry encountered..\n","\n","Some things to try:\n","a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n","b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n","c) Restart the kernel.\n"]}],"source":["brasileirao.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"875d4bc6-bd39-4c69-9de2-80e11f6f71bc","showTitle":false,"title":""},"vscode":{"languageId":"python"}},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"01-carregando-dados","widgets":{}},"kernelspec":{"display_name":"PySpark","language":"python","name":"pysparkkernel"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"pyspark","pygments_lexer":"python3"}},"nbformat":4,"nbformat_minor":0}
